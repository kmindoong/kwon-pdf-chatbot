import os
import json
import boto3
import streamlit as st
import logging
import base64
from dotenv import load_dotenv
from requests_aws4auth import AWS4Auth
from opensearchpy import OpenSearch, RequestsHttpConnection
from opensearchpy.helpers import bulk
from unstructured.partition.pdf import partition_pdf
from unstructured.documents.elements import Title, NarrativeText, ListItem, Image
from io import BytesIO
from opensearchpy.exceptions import NotFoundError, ConnectionError
from streamlit_pdf_viewer import pdf_viewer
import fitz  # PyMuPDF ë¼ì´ë¸ŒëŸ¬ë¦¬
from PIL import Image as PilImage # ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìš”
import pytesseract

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)

# ========================
# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# ========================
load_dotenv()

aws_access_key_id = os.getenv("AWS_ACCESS_KEY_ID")
aws_secret_access_key = os.getenv("AWS_SECRET_ACCESS_KEY")
aws_region = os.getenv("AWS_REGION")
s3_bucket_name = os.getenv("S3_BUCKET_NAME")
opensearch_host = os.getenv("OPENSEARCH_COLLECTION_HOST")
opensearch_index_name = os.getenv("OPENSEARCH_KWON_NAME2")
bedrock_model_id = os.getenv("BEDROCK_MODEL_ID")

if not all([aws_access_key_id, aws_secret_access_key, aws_region, s3_bucket_name, opensearch_host, opensearch_index_name, bedrock_model_id]):
    st.error("`.env` íŒŒì¼ì— í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë“  ë³€ìˆ˜ë¥¼ ì±„ì›Œì£¼ì„¸ìš”.")
    st.stop()

session = boto3.Session(
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key,
    region_name=aws_region
)
credentials = session.get_credentials()
awsauth = AWS4Auth(
    credentials.access_key,
    credentials.secret_key,
    aws_region,
    'aoss'
)

s3_client = session.client('s3')
bedrock_client = session.client('bedrock-runtime')
opensearch_client = OpenSearch(
    hosts=[{'host': opensearch_host, 'port': 443}],
    http_auth=awsauth,
    use_ssl=True,
    verify_certs=True,
    connection_class=RequestsHttpConnection,
    timeout=30
)

# PDF ë° ì´ë¯¸ì§€ ì €ì¥ í´ë” ì„¤ì • ë° ìƒì„±
PDF_DIR = "./multi-pdf-files"
FIGURES_DIR = "./images"
os.makedirs(PDF_DIR, exist_ok=True)
os.makedirs(FIGURES_DIR, exist_ok=True)

# ========================
# 2. ì¸ë±ì‹± í•¨ìˆ˜ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€) - ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬
# ========================

# í˜„ì¬ ì½”ë“œì—ì„œëŠ” unstructured ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. unstructuredëŠ” ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹ì— ë²”ìš©ì ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ë§Œ, PDF íŒŒì‹±ì— íŠ¹í™”ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ë¹ ë¥´ê³  ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# PyMuPDF (fitz): ì†ë„ì™€ ì •í™•ì„±ì´ ë§¤ìš° ë›°ì–´ë‚œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. PDFì˜ í…ìŠ¤íŠ¸ì™€ ë ˆì´ì•„ì›ƒ ì •ë³´ë¥¼ ë¹ ë¥´ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
# pdfplumber: í‘œ(table) ì¶”ì¶œ ê¸°ëŠ¥ì´ ê°•ë ¥í•˜ë©°, íŠ¹ì • ì˜ì—­ì˜ í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ë¥¼ ì„ íƒì ìœ¼ë¡œ íŒŒì‹±í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.
# PyMuPDFëŠ” PDFì˜ ë‚´ë¶€ì— í¬í•¨ëœ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ë° ë§¤ìš° íš¨ê³¼ì ì´ì§€ë§Œ, **ì´ë¯¸ì§€ì— í¬í•¨ëœ í…ìŠ¤íŠ¸(OCR)**ë¥¼ ì§ì ‘ ì¶”ì¶œí•˜ëŠ” ê¸°ëŠ¥ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
# ë”°ë¼ì„œ PyMuPDFë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì¶”ì¶œí•˜ë ¤ë©´, OCR ì—”ì§„ì„ ë³„ë„ë¡œ ì—°ë™í•´ì•¼ í•©ë‹ˆë‹¤.
# unstructured ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” tesseract-ocrê³¼ ê°™ì€ OCR ì—”ì§„ì„ ë°±ì—”ë“œë¡œ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. í˜„ì¬ ì½”ë“œê°€ ì´ë¯¸ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì œëŒ€ë¡œ ì¸ì‹í•˜ì§€ ëª»í•˜ëŠ” ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# Tesseract OCR ì—”ì§„ ë¯¸ì„¤ì¹˜: unstructured ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì˜ì¡´í•˜ëŠ” tesseract-ocrì´ EC2 ì¸ìŠ¤í„´ìŠ¤ì— ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ì–¸ì–´ íŒ© ë¶€ì¡±: Tesseractê°€ í•œê¸€ì„ ì¸ì‹í•˜ë ¤ë©´ í•œê¸€ ì–¸ì–´ íŒ©ì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
# ë‚®ì€ í•´ìƒë„: PDF ë¬¸ì„œì˜ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì €í•´ìƒë„ì¸ ê²½ìš°, OCR ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


def process_pdfs_and_index_opensearch():
    try:
        pdf_files = [f for f in os.listdir(PDF_DIR) if f.endswith(".pdf")]
        if not pdf_files:
            st.error(f"'{PDF_DIR}' í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        logging.info("OpenSearch ì¸ë±ìŠ¤ ì‚­ì œ ë° ìƒì„± ì¤‘...")
        if opensearch_client.indices.exists(index=opensearch_index_name):
            opensearch_client.indices.delete(index=opensearch_index_name)
            logging.info(f"ê¸°ì¡´ ì¸ë±ìŠ¤ '{opensearch_index_name}'ì„ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        
        mapping = {
            "settings": {
                "index.knn": True,
            },
            "mappings": {
                "properties": {
                    "text": {"type": "text"},
                    "embedding": {
                        "type": "knn_vector",
                        "dimension": 1536,
                        "method": {
                            "name": "hnsw",
                            "engine": "nmslib"
                        }
                    },
                    "image_paths": {"type": "keyword"},
                    "page_number": {"type": "long"},
                    "source": {"type": "keyword"}
                }
            }
        }
        opensearch_client.indices.create(index=opensearch_index_name, body=mapping)
        logging.info(f"OpenSearch ì¸ë±ìŠ¤ '{opensearch_index_name}' ìƒì„± ì™„ë£Œ.")

        docs = []
        for file_name in pdf_files:
            logging.info(f"'{file_name}' íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
            local_pdf_path = os.path.join(PDF_DIR, file_name)

            elements = partition_pdf(
                filename=local_pdf_path,
                strategy="hi_res",
                infer_table_structure=False,
                languages=["kor", "eng"],
                ocr_languages="kor+eng",
                extract_images_in_pdf=True,
                image_output_dir_path=FIGURES_DIR
            )
            
            chunks = []
            current_chunk_text = ""
            current_chunk_images = []
            current_chunk_page = 1 # <-- íŒŒì¼ë‹¹ í˜ì´ì§€ ë²ˆí˜¸ ì´ˆê¸°í™”
            
            for element in elements:
                # í˜ì´ì§€ ë²ˆí˜¸ ì—…ë°ì´íŠ¸
                if hasattr(element.metadata, 'page_number') and element.metadata.page_number:
                    current_chunk_page = element.metadata.page_number
                
                # ì´ë¯¸ì§€ ì²˜ë¦¬
                if isinstance(element, Image):
                    if hasattr(element.metadata, 'image_path'):
                        current_chunk_images.append(os.path.basename(element.metadata.image_path))
                    # OCR í…ìŠ¤íŠ¸ëŠ” unstructuredê°€ ìë™ìœ¼ë¡œ element.textì— í¬í•¨í•©ë‹ˆë‹¤.
                    if element.text and len(element.text) > 20:
                         current_chunk_text += "\n\nì´ë¯¸ì§€ ì„¤ëª…: " + element.text
                         
                # ì œëª©ì„ ê¸°ì¤€ìœ¼ë¡œ ì²­í¬ ë¶„ë¦¬
                elif isinstance(element, Title):
                    if current_chunk_text.strip():
                        chunks.append({
                            "text": current_chunk_text.strip(),
                            "image_paths": current_chunk_images,
                            "page_number": current_chunk_page
                        })
                    current_chunk_text = element.text
                    current_chunk_images = []
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ê°€
                elif isinstance(element, (NarrativeText, ListItem)):
                    current_chunk_text += "\n" + element.text
            
            # ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
            if current_chunk_text.strip():
                chunks.append({
                    "text": current_chunk_text.strip(),
                    "image_paths": current_chunk_images,
                    "page_number": current_chunk_page
                })
            
            for chunk in chunks:
                if not chunk['text']:
                    continue
                
                bedrock_model_id = 'amazon.titan-embed-text-v1'
                response = bedrock_client.invoke_model(
                    modelId=bedrock_model_id,
                    body=json.dumps({"inputText": chunk['text']})
                )
                embedding = json.loads(response['body'].read())['embedding']

                doc = {
                    'text': chunk['text'],
                    'source': file_name,
                    'page_number': chunk['page_number'],
                    'embedding': embedding,
                    'image_paths': chunk['image_paths']
                }
                docs.append({
                    '_index': opensearch_index_name,
                    '_source': doc
                })

        if docs:
            try:
                successes, failures = bulk(opensearch_client, docs)
                if failures:
                    logging.error(f"ì¸ë±ì‹± ì‹¤íŒ¨: {failures}")
                else:
                    logging.info(f"OpenSearchì— ì„±ê³µì ìœ¼ë¡œ ì¸ë±ì‹±ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë¬¸ì„œ ìˆ˜: {len(docs)}")
            except ConnectionError as e:
                logging.error(f"ë²Œí¬ ì¸ë±ì‹± ì¤‘ ì—°ê²° ì˜¤ë¥˜: {e}")
            except Exception as e:
                logging.error(f"ë²Œí¬ ì¸ë±ì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            logging.warning("ì¸ë±ì‹±í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        logging.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

def get_rag_answer_from_bedrock_with_images(query):
    try:
        # LLM ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ í™•ì¥ (Haiku ëª¨ë¸ ì‚¬ìš©)
        llm_model_id_expansion = 'anthropic.claude-3-haiku-20240307-v1:0'
        expansion_prompt = f"""
        ì£¼ì–´ì§„ ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ì´ê³  í’ë¶€í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ í™•ì¥í•´ì¤˜.
        ë‹¨, ì›ë˜ ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•´.
        
        ì˜ˆì‹œ:
        - ì›ë³¸ ì§ˆë¬¸: "ë¡œê·¸ì¸ ê³„ì •ì€?"
        - í™•ì¥ ì¿¼ë¦¬: "Azure ìê²©ì¦ ì‹ ì²­ ì‹œ ë¡œê·¸ì¸ ê³„ì •"

        ì›ë³¸ ì§ˆë¬¸: {query}
        í™•ì¥ ì¿¼ë¦¬: 
        """
        body_expansion = json.dumps({
            "anthropic_version": "bedrock-2023-05-31", 
            "max_tokens": 100, 
            "messages": [{"role": "user", "content": [{"type": "text", "text": expansion_prompt}]}], 
            "temperature": 0.5
        })
        response_body_expansion = bedrock_client.invoke_model(
            modelId=llm_model_id_expansion, 
            body=body_expansion, 
            contentType="application/json", 
            accept="application/json"
        )
        expanded_query = json.loads(response_body_expansion.get('body').read())['content'][0]['text']
        
        # í™•ì¥ëœ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ìƒì„±
        bedrock_model_id_embedding = 'amazon.titan-embed-text-v1'
        response_embedding = bedrock_client.invoke_model(
            modelId=bedrock_model_id_embedding,
            body=json.dumps({"inputText": expanded_query})
        )
        query_embedding = json.loads(response_embedding['body'].read())['embedding']
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ íŠœë‹: í™•ì¥ëœ ì¿¼ë¦¬ì— ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬
        search_query = {
            "size": 3,
            "query": {
                "bool": {
                    "should": [
                        {
                            "multi_match": {
                                "query": expanded_query,
                                "fields": ["text"] # í™•ì¥ëœ ì¿¼ë¦¬ì— 3ë°° ê°€ì¤‘ì¹˜ ë¶€ì—¬
                            }
                        },
                        {
                            "knn": {
                                "embedding": {
                                    "vector": query_embedding,
                                    "k": 3
                                }
                            }
                        }
                    ],
                    "minimum_should_match": 1
                }
            },
            "_source": ["text", "image_paths"]
        }
        
        response = opensearch_client.search(index=opensearch_index_name, body=search_query)
        hits = response['hits']['hits']
        context_docs = []
        image_paths = []
        
        for hit in hits:
            context_docs.append(hit['_source']['text'])
            if 'image_paths' in hit['_source'] and hit['_source']['image_paths']:
                image_paths.extend(hit['_source']['image_paths'])
        
        if not context_docs:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

        context = "\n\n".join(context_docs)
        
        # LLM ëª¨ë¸ í˜¸ì¶œ
        llm_model_id = 'anthropic.claude-3-haiku-20240307-v1:0'
        
        if 'claude' in llm_model_id:
            prompt = f"""
            ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•œ ì°¸ê³  ìë£Œì…ë‹ˆë‹¤.
            <ìë£Œ>
            {context}
            </ìë£Œ>
            ë‹¹ì‹ ì€ ìœ ìš©í•œ AI ë¹„ì„œì…ë‹ˆë‹¤. ì œê³µëœ ìë£Œë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. ë§Œì•½ ìë£Œì— ë‹µë³€ì´ ì—†ë‹¤ë©´, "ì£„ì†¡í•©ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œì—ëŠ” ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë§í•´ì£¼ì„¸ìš”. ì ˆëŒ€ ìë£Œì— ì—†ëŠ” ì •ë³´ë¥¼ ì„ì˜ë¡œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
            ì‚¬ìš©ì ì§ˆë¬¸: {query}
            ë‹µë³€:
            """
            body = json.dumps({"anthropic_version": "bedrock-2023-05-31", "max_tokens": 1000, "messages": [{"role": "user", "content": [{"type": "text", "text": prompt}]}], "temperature": 0.5})
            response_body = bedrock_client.invoke_model(modelId=llm_model_id, body=body, contentType="application/json", accept="application/json")
            llm_answer = json.loads(response_body.get('body').read())['content'][0]['text']
        else:
            prompt = f"""
            You are a helpful AI assistant. Use only the provided context to answer the user's question in Korean. If the answer is not in the context, say "ì£„ì†¡í•©ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œì—ëŠ” ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤." Do not make up information.
            Context:
            {context}
            Question: {query}
            Answer:
            """
            body = json.dumps({"inputText": prompt, "textGenerationConfig": {"maxTokenCount": 1000, "stopSequences": [], "temperature": 0.5, "topP": 0.9}})
            response_body = bedrock_client.invoke_model(modelId=llm_model_id, body=body)
            llm_answer = json.loads(response_body.get('body').read())['results'][0]['outputText']

        unique_image_paths = list(set(image_paths))
        return llm_answer, unique_image_paths

    except Exception as e:
        return f"RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", []

# ========================
# 4. Streamlit ì•± ë¡œì§
# ========================
st.set_page_config(layout="wide")
st.title("S3 ê¸°ë°˜ ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if 'text_input_value' not in st.session_state:
    st.session_state['text_input_value'] = ""
if 'pdf_page_number' not in st.session_state:
    st.session_state['pdf_page_number'] = 1

# PDF ë·°ì–´ì™€ ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ë¥¼ ë‘ ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
col1, col2 = st.columns([1, 1])

with col1:
    st.markdown("## PDF ë¯¸ë¦¬ë³´ê¸° ë·°ì–´ (ì²«ë²ˆì§¸ íŒŒì¼ë§Œ ë³´ì´ì§€ë¡±)", unsafe_allow_html=True)
    
    # multi-pdf-files í´ë”ì—ì„œ PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    pdf_files = [f for f in os.listdir(PDF_DIR) if f.endswith(".pdf")]
    
    if pdf_files:
        pdf_path = os.path.join(PDF_DIR, pdf_files[0]) # ì²« ë²ˆì§¸ íŒŒì¼ë§Œ ë¯¸ë¦¬ë³´ê¸°
        with open(pdf_path, "rb") as f:
            pdf_file_data = f.read()

        # í˜ì´ì§€ ë„˜ê¸°ê¸° ë²„íŠ¼ ì¶”ê°€
        page_prev, page_info, page_next = st.columns([1, 1, 1])
        with page_prev:
            if st.button("ì´ì „ í˜ì´ì§€"):
                if st.session_state.pdf_page_number > 1:
                    st.session_state.pdf_page_number -= 1
                    st.rerun()
        with page_info:
            st.markdown(f"**í˜ì´ì§€: {st.session_state.pdf_page_number}**", unsafe_allow_html=True)
        with page_next:
            if st.button("ë‹¤ìŒ í˜ì´ì§€"):
                if st.session_state.pdf_page_number < 10: # ìµœëŒ€ 10í˜ì´ì§€ ë¯¸ë¦¬ë³´ê¸°
                    st.session_state.pdf_page_number += 1
                    st.rerun()
        
        pdf_viewer(
            input=pdf_file_data, 
            pages_to_render=[st.session_state.pdf_page_number]
        )
    else:
        st.warning(f"'{PDF_DIR}' í´ë”ì— PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ì‹±ì„ ì§„í–‰í•˜ë©´ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.")

with col2:
    index_exists = True
    try:
        opensearch_client.indices.get(index=opensearch_index_name)
    except NotFoundError:
        index_exists = False
    
    # ì¸ë±ì‹± ì‹œì‘ ë²„íŠ¼ ë¡œì§ ìˆ˜ì •
    if not index_exists:
        st.warning(f"OpenSearch ì¸ë±ìŠ¤ '{opensearch_index_name}'ì´(ê°€) ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. PDF ì¸ë±ì‹±ì„ ë¨¼ì € ì§„í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")

        # ì¸ë±ì‹± ì‘ì—… ì¤‘ì¸ì§€ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        if 'is_indexing' not in st.session_state:
            st.session_state.is_indexing = False
        
        # ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ is_indexing ìƒíƒœë¥¼ Trueë¡œ ë³€ê²½
        if st.button("PDF ì¸ë±ì‹± ì‹œì‘", disabled=st.session_state.is_indexing):
            st.session_state.is_indexing = True
            st.rerun()

        # is_indexing ìƒíƒœê°€ Trueì¼ ë•Œë§Œ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ë° ìŠ¤í”¼ë„ˆ í‘œì‹œ
        if st.session_state.is_indexing:
            with st.spinner("PDFë¥¼ ì¸ë±ì‹±í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
                process_pdfs_and_index_opensearch()
                st.session_state.is_indexing = False # ì¸ë±ì‹± ì™„ë£Œ í›„ ìƒíƒœ ì´ˆê¸°í™”
                st.success("ğŸ‰ PDF ì¸ë±ì‹±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì±—ë´‡ì— ì§ˆë¬¸í•´ ë³´ì„¸ìš”.")
                st.rerun()

    else:
        st.success(f"OpenSearch ì¸ë±ìŠ¤ '{opensearch_index_name}'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë°”ë¡œ ì§ˆë¬¸í•´ ë³´ì„¸ìš”.")
        
        st.markdown("---")
        st.markdown("## ìƒ˜í”Œ ì§ˆë¬¸ (í´ë¦­í•˜ê³  ë§¨ ì•„ë˜ ì§ˆë¬¸ ë³´ë‚´ê¸° ë²„íŠ¼ í´ë¦­)")

        sample_questions = [
            "ì—­ëŸ‰ self profilingì˜ Skill set ë‹¨ê³„ê°€ ë¬´ì—‡ì´ ìˆìœ¼ë©° ê° ë‹¨ê³„ë³„ ì˜ë¯¸ë¥¼ ì•Œë ¤ì¤˜",
            "ì—­ëŸ‰ self profiling ë¬¸ì˜ê°€ ìƒê¸°ë©´ ì–´ë””ë‹¤ê°€ ì—°ë½í•˜ë©´ ë¼?",
            "ì—­ëŸ‰ self profiling ë„ì… ë°°ê²½ì€?",
            "ì§ë¬´ ë“±ê¸‰ ê²°ê³¼ëŠ” ì–¸ì œ ì˜¤í”ˆ ë˜ë‹ˆ?",
            "íŒ€ì›ì˜ Skill set ì¡°íšŒì™€ ì§ë¬´ëŠ” ì–´ë””ì„œ í™•ì¸í•  ìˆ˜ ìˆë‚˜?",
            "ë¡¯ë°ì˜¨ì˜ íŒë§¤ê°€ê²© ë° ì¬ê³ ìˆ˜ëŸ‰ ì„¤ì • ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì•Œë ¤ì¤˜.",
            "ë¡¯ë°ì˜¨ì˜ ë°°ì†¡/ë°˜í’ˆì •ë³´ì—ì„œ ë°°ì†¡ì •ë³´ ì„¤ì • ë°©ë²• ì•Œë ¤ì¤˜.",
            "ë¡¯ë°ì˜¨ì˜ FAQë¥¼ ì•Œë ¤ì¤˜.",
            "Azure ìê²©ì¦ ì‹œí—˜ ì‹ ì²­ ë°©ë²• ì•Œë ¤ì¤˜.",
            "Azure ìê²©ì¦ íšë“ í›„ MPN ì—°ë™ ë°©ë²• ì•Œë ¤ì¤˜.",
            "Azure ìê²©ì¦ ì‹ ì²­í•  ë•Œ ë¡œê·¸ì¸ ê³„ì •ì€?"
        ]
        
        cols = st.columns(2)
        for i, q in enumerate(sample_questions):
            with cols[i % 2]:
                if st.button(q, key=f"btn_{i}"):
                    st.session_state.text_input_value = q
                    st.rerun()
        st.write("---")
        
        # ë³€ê²½ëœ ë¶€ë¶„: ì´ì „ ëŒ€í™” ê¸°ë¡ì€ expanderë¡œ, ë§ˆì§€ë§‰ ëŒ€í™”ëŠ” ê·¸ëŒ€ë¡œ í‘œì‹œ
        if len(st.session_state.messages) > 2:
            for i in range(0, len(st.session_state.messages) - 2, 2):
                user_message = st.session_state.messages[i]
                assistant_message = st.session_state.messages[i+1]
                
                with st.expander(f"Q: {user_message['content'][:50]}..."):
                    st.markdown(f"**ì§ˆë¬¸**: {user_message['content']}")
                    st.markdown(f"**ë‹µë³€**: {assistant_message['content']}")
                    if "images" in assistant_message and assistant_message["images"]:
                        for image_path in assistant_message["images"]:
                            st.image(image_path)
        
        # ë§ˆì§€ë§‰ ëŒ€í™”ë§Œ ë”°ë¡œ í‘œì‹œ (ìë™ìœ¼ë¡œ ì ‘íˆì§€ ì•ŠìŒ)
        if st.session_state.messages:
            last_user_message = st.session_state.messages[-2]
            last_assistant_message = st.session_state.messages[-1]
            
            with st.chat_message(last_user_message["role"]):
                st.markdown(last_user_message["content"])
            with st.chat_message(last_assistant_message["role"]):
                st.markdown(last_assistant_message["content"])
                if "images" in last_assistant_message and last_assistant_message["images"]:
                    for image_path in last_assistant_message["images"]:
                        st.image(image_path)

    if index_exists:
        with st.form(key='chat_form', clear_on_submit=True):
            submit_button_label = "ì „ì†¡"
            if st.session_state.text_input_value:
                submit_button_label = "ğŸŒŸ ì§ˆë¬¸ ë³´ë‚´ê¸°"
            
            user_input = st.text_input(
                "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...", 
                value=st.session_state.text_input_value, 
                key='user_input_key',
                label_visibility='hidden'
            )
            submit_button = st.form_submit_button(submit_button_label)
        
        if submit_button and user_input:
            st.session_state.text_input_value = ""
            st.session_state.messages.append({"role": "user", "content": user_input})
            with st.chat_message("user"):
                st.markdown(user_input)

            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    answer, image_paths = get_rag_answer_from_bedrock_with_images(user_input)
                    st.markdown(answer)
                    if image_paths:
                        for image_path in image_paths:
                            st.image(os.path.join(FIGURES_DIR, image_path), caption=os.path.basename(image_path))
            
            st.session_state.messages.append({"role": "assistant", "content": answer, "images": [os.path.join(FIGURES_DIR, p) for p in image_paths]})
            st.rerun()