{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install boto3 opensearch-py python-dotenv unstructured pdf2image pillow streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "aws_region = os.getenv(\"AWS_REGION\")\n",
    "\n",
    "# AWS 자격 증명 및 서명 설정\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=aws_region\n",
    ")\n",
    "credentials = session.get_credentials()\n",
    "awsauth = AWS4Auth(\n",
    "    credentials.access_key,\n",
    "    credentials.secret_key,\n",
    "    aws_region,\n",
    "    'aoss' # Amazon OpenSearch Serverless 서비스명\n",
    ")\n",
    "\n",
    "s3_client = session.client('s3')\n",
    "bedrock_client = session.client('bedrock-runtime')\n",
    "s3_bucket_name = os.getenv(\"S3_BUCKET_NAME\")\n",
    "\n",
    "# OpenSearch Serverless 클라이언트 설정\n",
    "opensearch_host = os.getenv(\"OPENSEARCH_COLLECTION_HOST\")\n",
    "opensearch_index_name = os.getenv(\"OPENSEARCH_TEST_INDEX_NAME\")\n",
    "opensearch_client = OpenSearch(\n",
    "    hosts=[{'host': opensearch_host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def upload_pdf_to_s3(file_path):\n",
    "    \"\"\"\n",
    "    로컬 PDF 파일을 S3 버킷에 업로드합니다.\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    try:\n",
    "        s3_client.upload_file(file_path, s3_bucket_name, file_name)\n",
    "        print(f\"'{file_name}' 파일이 S3 버킷 '{s3_bucket_name}'에 성공적으로 업로드되었습니다.\")\n",
    "        return file_name\n",
    "    except Exception as e:\n",
    "        print(f\"S3 업로드 중 오류 발생: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'accu.pdf' 파일이 S3 버킷 'mjkwon-s3'에 성공적으로 업로드되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 업로드할 PDF 파일 경로 지정 (예시)\n",
    "local_pdf_path = \"pdf-files/accu.pdf\"\n",
    "s3_file_name = upload_pdf_to_s3(local_pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade unstructured unstructured-inference opensearch-py\n",
    "# !pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\"\n",
    "# !pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opensearch_index_name = os.getenv(\"OPENSEARCH_TEST_INDEX_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_pdf_and_index_opensearch 함수를 나누어 실행하는 첫 번째 셀\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "from opensearchpy.helpers import bulk\n",
    "from opensearchpy.exceptions import NotFoundError\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from io import BytesIO\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# s3_file_name = \"accu.pdf\"  # 예시 파일명\n",
    "\n",
    "# unstructured 파편화 문제 해결\n",
    "# 가장 근본적인 원인은 unstructured 라이브러리가 PDF의 레이아웃(특히 이미지 내 텍스트나 복잡한 표)을 제대로 인식하지 못하고 파편화된 텍스트를 생성했기 때문입니다. 이 문제는 단순한 텍스트 검색(keyword search)으로는 해결하기 어렵습니다.\n",
    "\n",
    "# 2. 해결 방법: 벡터 검색(k-NN) 도입\n",
    "# 텍스트 파편화 문제를 해결하고 질문의 의미를 정확하게 파악하기 위해서는 **벡터 검색(k-NN)**을 도입하는 것이 가장 효과적입니다. 벡터 검색은 텍스트의 의미를 숫자로 표현한 벡터를 생성하고, 질문 벡터와 가장 유사한 문서 벡터를 찾아냅니다.\n",
    "\n",
    "# try:\n",
    "#     print(\"1. S3에서 PDF 파일 다운로드 중...\")\n",
    "#     s3_object = s3_client.get_object(Bucket=s3_bucket_name, Key=s3_file_name)\n",
    "#     pdf_content = s3_object['Body'].read()\n",
    "#     print(\"다운로드 완료.\")\n",
    "\n",
    "#     print(\"2. unstructured를 사용하여 PDF 내용 분할 중...\")\n",
    "#     elements = partition_pdf(\n",
    "#         file=BytesIO(pdf_content),\n",
    "#         strategy=\"hi_res\",\n",
    "#         infer_table_structure=False,\n",
    "#         languages=[\"kor\", \"eng\"],\n",
    "#         extract_images_in_pdf=True,\n",
    "#         image_output_dir_path=\"./images\"\n",
    "#     )\n",
    "#     print(f\"unstructured 분할 완료. 추출된 요소 수: {len(elements)}\")\n",
    "\n",
    "#     print(\"---\")\n",
    "#     print(\"첫 번째 단계 성공. 다음 셀로 이동하세요.\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"**오류 발생 (1단계): {e}**\")\n",
    "\n",
    "\n",
    "# 필요한 작업:\n",
    "# 임베딩 모델 선택: Bedrock의 titan-embed-text-v1과 같은 텍스트 임베딩 모델을 사용합니다.\n",
    "# 임베딩 벡터 생성: PDF에서 추출한 각 텍스트 청크(chunk)를 임베딩 모델에 넣어 벡터로 변환합니다.\n",
    "# OpenSearch에 벡터 저장: 텍스트와 함께 벡터를 OpenSearch 인덱스에 저장합니다.\n",
    "# 검색 쿼리 수정: 사용자 질문을 벡터로 변환한 후, OpenSearch의 knn 쿼리를 사용해 유사한 벡터를 가진 문서를 검색합니다.\n",
    "\n",
    "# 텍스트 청킹(Chunking) 전략: unstructured가 추출한 텍스트를 문장이나 단락 단위로 묶는 추가적인 전처리 과정을 거쳐 임베딩의 품질을 높입니다.\n",
    "\n",
    "def process_pdf_and_index_opensearch_with_embeddings(s3_file_name):\n",
    "\n",
    "    try:\n",
    "            \n",
    "            # S3에서 PDF 다운로드\n",
    "            s3_object = s3_client.get_object(Bucket=s3_bucket_name, Key=s3_file_name)\n",
    "            pdf_content = s3_object['Body'].read()\n",
    "\n",
    "            # unstructured로 PDF 내용 분할\n",
    "            elements = partition_pdf(\n",
    "                file=BytesIO(pdf_content),\n",
    "                strategy=\"hi_res\",\n",
    "                infer_table_structure=False,\n",
    "                languages=[\"kor\", \"eng\"],\n",
    "                extract_images_in_pdf=True,\n",
    "                image_output_dir_path=\"./figures\"\n",
    "            )\n",
    "\n",
    "            # 텍스트 청킹을 위한 전처리\n",
    "            text_content = \"\\n\".join([el.text for el in elements if el.text])\n",
    "            ## 청크 크기 조절 필요\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            chunks = text_splitter.split_text(text_content)\n",
    "\n",
    "            # 인덱스 존재 여부를 확인하는 새로운 방식\n",
    "            index_exists = True\n",
    "            try:\n",
    "                opensearch_client.indices.get(index=opensearch_index_name)\n",
    "            except NotFoundError:\n",
    "                index_exists = False\n",
    "\n",
    "            if index_exists:\n",
    "                print(f\"OpenSearch 인덱스 '{opensearch_index_name}'이(가) 이미 존재합니다.\")\n",
    "                opensearch_client.indices.delete(index=opensearch_index_name)\n",
    "                print(f\"OpenSearch 인덱스 '{opensearch_index_name}'이(가) 삭제 완료\")\n",
    "            # else:\n",
    "            #     print(f\"OpenSearch 인덱스 '{opensearch_index_name}'이(가) 존재하지 않습니다. 새로 생성합니다.\")\n",
    "            #     opensearch_client.indices.create(index=opensearch_index_name)\n",
    "            #     print(f\"OpenSearch 인덱스 '{opensearch_index_name}' 생성 완료.\")\n",
    "            \n",
    "            # print(\"---\")\n",
    "\n",
    "            else:\n",
    "                print(f\"OpenSearch 인덱스 '{opensearch_index_name}'이(가) 존재하지 않습니다. 새로 생성합니다.\")\n",
    "                mapping = {\n",
    "                    \"settings\": {\n",
    "                        \"index.knn\": True,\n",
    "                    },\n",
    "                    \"mappings\": {\n",
    "                        \"properties\": {\n",
    "                            \"text\": {\"type\": \"text\"},\n",
    "                            \"embedding\": {\n",
    "                                \"type\": \"knn_vector\",\n",
    "                                \"dimension\": 1024, # Cohere 모델 차원 수\n",
    "                                \"method\": {\n",
    "                                    \"name\": \"hnsw\",\n",
    "                                    \"engine\": \"nmslib\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            opensearch_client.indices.create(index=opensearch_index_name, body=mapping)\n",
    "            print(f\"OpenSearch 인덱스 '{opensearch_index_name}' 생성 완료.\")\n",
    "\n",
    "            \n",
    "            # OpenSearch 인덱스 존재 여부 확인 및 생성 (에러 발생: OpenSearch 인덱싱 중 오류 발생: IndicesClient.exists() takes 1 positional argument but 2 positional arguments (and 2 keyword-only arguments) were given\n",
    "            # if not opensearch_client.indices.exists(opensearch_index_name):\n",
    "            #     # 벡터 검색을 위한 매핑 정보 포함\n",
    "            #     mapping = {\n",
    "            #         \"settings\": {\n",
    "            #             \"index.knn\": True\n",
    "            #         },\n",
    "            #         \"mappings\": {\n",
    "            #             \"properties\": {\n",
    "            #                 \"text\": {\"type\": \"text\"},\n",
    "            #                 \"embedding\": {\n",
    "            #                     \"type\": \"knn_vector\",\n",
    "            #                     \"dimension\": 1536, # Titan Embed Text 모델 차원 수\n",
    "            #                     \"method\": {\n",
    "            #                         \"name\": \"hnsw\",\n",
    "            #                         \"engine\": \"nmslib\"\n",
    "            #                     }\n",
    "            #                 }\n",
    "            #             }\n",
    "            #         }\n",
    "            #     }\n",
    "            #     opensearch_client.indices.create(index=opensearch_index_name, body=mapping)\n",
    "            #     print(f\"OpenSearch 인덱스 '{opensearch_index_name}' 생성 완료.\")\n",
    "\n",
    "            docs = []\n",
    "            # for i, el in enumerate(elements):\n",
    "            #     text = el.text if el.text else \"\"\n",
    "            #     if text:\n",
    "            #         # Bedrock Titan Embeddings 모델 호출\n",
    "            #         bedrock_model_id = 'amazon.titan-embed-text-v1'\n",
    "            #         response = bedrock_client.invoke_model(\n",
    "            #             modelId=bedrock_model_id,\n",
    "            #             body=json.dumps({\"inputText\": text})\n",
    "            #         )\n",
    "            #         embedding = json.loads(response['body'].read())['embedding']\n",
    "\n",
    "            #         doc = {\n",
    "            #             'text': text,\n",
    "            #             'source': s3_file_name,\n",
    "            #             'page_number': el.metadata.page_number if hasattr(el.metadata, 'page_number') else None,\n",
    "            #             'embedding': embedding\n",
    "            #         }\n",
    "            #         docs.append({\n",
    "            #             '_index': opensearch_index_name,\n",
    "            #             '_source': doc\n",
    "            #         })\n",
    "\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                bedrock_model_id = 'cohere.embed-multilingual-v3'\n",
    "                response = bedrock_client.invoke_model(\n",
    "                    modelId=bedrock_model_id,\n",
    "                    body=json.dumps({\"texts\": [chunk], \"input_type\": \"search_document\"})\n",
    "                )\n",
    "                embedding = json.loads(response['body'].read())['embeddings'][0]\n",
    "\n",
    "                doc = {\n",
    "                'text': chunk,\n",
    "                'source': s3_file_name,\n",
    "                'page_number': i + 1,\n",
    "                'embedding': embedding\n",
    "            }\n",
    "            docs.append({\n",
    "                '_index': opensearch_index_name,\n",
    "                '_source': doc\n",
    "            })\n",
    "\n",
    "            bulk(opensearch_client, docs)\n",
    "            print(f\"PDF 내용이 OpenSearch에 성공적으로 인덱싱되었습니다. 문서 수: {len(docs)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"OpenSearch 인덱싱 중 오류 발생: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "short text: \"Acculnsight+ 2.0 #e2|At WS\". Defaulting to English.\n",
      "short text: \"2021. 09 DataSet\". Defaulting to English.\n",
      "short text: \"i SK SIA} C&C\". Defaulting to English.\n",
      "short text: \"01 ZRAE Fel\". Defaulting to English.\n",
      "short text: \"PIPELINE\". Defaulting to English.\n",
      "short text: \"/Q |\". Defaulting to English.\n",
      "short text: \"demo-for-mosiler\". Defaulting to English.\n",
      "short text: \";\". Defaulting to English.\n",
      "short text: \"=\". Defaulting to English.\n",
      "short text: \"test22\". Defaulting to English.\n",
      "short text: \"AAS\". Defaulting to English.\n",
      "short text: \"0\". Defaulting to English.\n",
      "short text: \";\". Defaulting to English.\n",
      "short text: \"| 01\". Defaulting to English.\n",
      "short text: \"[HO OS o [He\". Defaulting to English.\n",
      "short text: \"Jlo\". Defaulting to English.\n",
      "short text: \"|\". Defaulting to English.\n",
      "short text: \"Jlo\". Defaulting to English.\n",
      "short text: \"PIPELINE\". Defaulting to English.\n",
      "short text: \"01 BAAR tel\". Defaulting to English.\n",
      "short text: \"PIPELINE\". Defaulting to English.\n",
      "short text: \"03 HABeFP. Fil\". Defaulting to English.\n",
      "short text: \"PIPELINE\". Defaulting to English.\n",
      "short text: \"Select Project\". Defaulting to English.\n",
      "short text: \"03 HALO Beal\". Defaulting to English.\n",
      "short text: \"PIPELINE\". Defaulting to English.\n",
      "short text: \"wu\". Defaulting to English.\n",
      "short text: \"PIPELINE\". Defaulting to English.\n",
      "short text: \"PIPELINE\". Defaulting to English.\n",
      "short text: \"ISH o\". Defaulting to English.\n",
      "short text: \"04 AFHA; Ast Zte|\". Defaulting to English.\n",
      "short text: \"4\". Defaulting to English.\n",
      "short text: \"PIPELINE\". Defaulting to English.\n",
      "short text: \"PIPELINE\". Defaulting to English.\n",
      "short text: \"05 AFSAt Ol zt\". Defaulting to English.\n",
      "short text: \"PIPELINE\". Defaulting to English.\n",
      "short text: \"Select Project\". Defaulting to English.\n",
      "short text: \"ae{4F\". Defaulting to English.\n",
      "short text: \"wate\". Defaulting to English.\n",
      "short text: \"ASAT 0] Zt\". Defaulting to English.\n",
      "short text: \"ag\". Defaulting to English.\n",
      "short text: \"A718\". Defaulting to English.\n",
      "short text: \"oleh St AKA Ais\". Defaulting to English.\n",
      "short text: \"10\". Defaulting to English.\n",
      "short text: \"01 ZRAE Fel\". Defaulting to English.\n",
      "short text: \"MODELER\". Defaulting to English.\n",
      "short text: \"11\". Defaulting to English.\n",
      "short text: \"r\". Defaulting to English.\n",
      "short text: \"2] Resource Quota\". Defaulting to English.\n",
      "short text: \"3) Members\". Defaulting to English.\n",
      "short text: \"MODELER\". Defaulting to English.\n",
      "short text: \"O02 AfSA} Bel\". Defaulting to English.\n",
      "short text: \"MODELER\". Defaulting to English.\n",
      "short text: \"13\". Defaulting to English.\n",
      "short text: \"Ba 02 AFSAt\". Defaulting to English.\n",
      "short text: \"= Ly ial aa\". Defaulting to English.\n",
      "short text: \"Jlo (e)\". Defaulting to English.\n",
      "short text: \"WI ra l4| ral\". Defaulting to English.\n",
      "short text: \"_ zt (e)\". Defaulting to English.\n",
      "short text: \"MODELER\". Defaulting to English.\n",
      "short text: \"03 GAY oOlOlA| ete]\". Defaulting to English.\n",
      "short text: \"MODELER\". Defaulting to English.\n",
      "short text: \"221\". Defaulting to English.\n",
      "short text: \"15\". Defaulting to English.\n",
      "short text: \"03 GAY oOlOlA| ete]\". Defaulting to English.\n",
      "short text: \"@ AHA 00/4) Be\". Defaulting to English.\n",
      "short text: \"Xt 2 oO\". Defaulting to English.\n",
      "short text: \"Aus Aa re\". Defaulting to English.\n",
      "short text: \"MODELER\". Defaulting to English.\n",
      "short text: \"End of Document\". Defaulting to English.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSearch 인덱스 'test-index'이(가) 존재하지 않습니다. 새로 생성합니다.\n",
      "OpenSearch 인덱스 'test-index' 생성 완료.\n",
      "PDF 내용이 OpenSearch에 성공적으로 인덱싱되었습니다. 문서 수: 1\n"
     ]
    }
   ],
   "source": [
    "# 함수 호출\n",
    "process_pdf_and_index_opensearch_with_embeddings(s3_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_answer_from_bedrock_with_embeddings(query):\n",
    "    try:\n",
    "        # 1. 사용자 질문을 임베딩 벡터로 변환\n",
    "        # bedrock_model_id = 'amazon.titan-embed-text-v1'\n",
    "        # response = bedrock_client.invoke_model(\n",
    "        #     modelId=bedrock_model_id,\n",
    "        #     body=json.dumps({\"inputText\": query})\n",
    "        # )\n",
    "        # query_embedding = json.loads(response['body'].read())['embedding']\n",
    "\n",
    "        # chunking, 사용자 질문을 임베딩 벡터로 변환\n",
    "        bedrock_model_id_embedding = 'cohere.embed-multilingual-v3'\n",
    "        print(f\"임베딩 모델: {bedrock_model_id_embedding}\")\n",
    "\n",
    "        response = bedrock_client.invoke_model(\n",
    "            modelId=bedrock_model_id_embedding,\n",
    "            body=json.dumps({\"texts\": [query], \"input_type\": \"search_query\"})\n",
    "        )\n",
    "        query_embedding = json.loads(response['body'].read())['embeddings'][0]\n",
    "        \n",
    "        # 2. OpenSearch에서 벡터 검색 (k-NN)\n",
    "        # search_query = {\n",
    "        #     \"size\": 5,\n",
    "        #     \"query\": {\n",
    "        #         \"knn\": {\n",
    "        #             \"embedding\": {\n",
    "        #                 \"vector\": query_embedding,\n",
    "        #                 \"k\": 5\n",
    "        #             }\n",
    "        #         }\n",
    "        #     },\n",
    "        #     \"_source\": [\"text\"] # 텍스트 필드만 가져와서 컨텍스트로 사용\n",
    "        # }\n",
    "\n",
    "        # 2. OpenSearch에서 하이브리드 검색 (knn + multi_match)\n",
    "        search_query = {\n",
    "            \"size\": 5,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\": [\n",
    "                        {\n",
    "                            \"multi_match\": {\n",
    "                                \"query\": query,\n",
    "                                \"fields\": [\"text^2\"],\n",
    "                                \"type\": \"best_fields\"\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"knn\": {\n",
    "                                \"embedding\": {\n",
    "                                    \"vector\": query_embedding,\n",
    "                                    \"k\": 5\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"minimum_should_match\": 1 # 하나라도 일치하면 문서 반환\n",
    "                }\n",
    "            },\n",
    "            \"_source\": [\"text\"]\n",
    "        }\n",
    "\n",
    "        # print(f\"\\nOpenSearch 검색 쿼리:\\n{json.dumps(search_query, indent=2, ensure_ascii=False)}\")\n",
    "\n",
    "        response = opensearch_client.search(index=opensearch_index_name, body=search_query)\n",
    "        hits = response['hits']['hits']\n",
    "        context_docs = [hit['_source']['text'] for hit in hits]\n",
    "        \n",
    "        print(f\"\\n검색된 문서 수: {len(hits)}개\")\n",
    "        for i, doc in enumerate(context_docs):\n",
    "            print(f\"--- 검색된 문서 #{i+1} ---\\n{doc}\\n------------------------\")\n",
    "        \n",
    "        if not context_docs:\n",
    "            print(\"관련 문서를 찾지 못했습니다. Bedrock에 전달할 컨텍스트가 없습니다.\")\n",
    "            return \"죄송합니다. 질문에 대한 관련 문서를 찾을 수 없습니다.\"\n",
    "\n",
    "        context = \"\\n\\n\".join(context_docs)\n",
    "        \n",
    "        # 3. Bedrock LLM에 프롬프트 전달\n",
    "        llm_model_id = os.getenv(\"BEDROCK_MODEL_ID\")\n",
    "        print(f\"\\nBedrock 모델: {llm_model_id}\")\n",
    "\n",
    "        if 'claude' in llm_model_id:\n",
    "            prompt = f\"\"\"\n",
    "            다음은 사용자 질문에 답변하기 위한 참고 자료입니다.\n",
    "            <자료>\n",
    "            {context}\n",
    "            </자료>\n",
    "            당신은 유용한 AI 비서입니다. 제공된 자료만을 바탕으로 사용자의 질문에 한국어로 상세하고 친절하게 답변해주세요. 만약 자료에 답변이 없다면, \"죄송합니다. 제공된 문서에는 답변이 없습니다.\"라고 말해주세요. 절대 자료에 없는 정보를 임의로 생성하지 마세요.\n",
    "            사용자 질문: {query}\n",
    "            답변:\n",
    "            \"\"\"\n",
    "            body = json.dumps({\"anthropic_version\": \"bedrock-2023-05-31\", \"max_tokens\": 1000, \"messages\": [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}], \"temperature\": 0.5})\n",
    "            response_body = bedrock_client.invoke_model(modelId=llm_model_id, body=body, contentType=\"application/json\", accept=\"application/json\")\n",
    "            llm_answer = json.loads(response_body.get('body').read())['content'][0]['text']\n",
    "\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "            You are a helpful AI assistant. Use only the provided context to answer the user's question in Korean. If the answer is not in the context, say \"죄송합니다. 제공된 문서에는 답변이 없습니다.\" Do not make up information.\n",
    "            Context:\n",
    "            {context}\n",
    "            Question: {query}\n",
    "            Answer:\n",
    "            \"\"\"\n",
    "            body = json.dumps({\"inputText\": prompt, \"textGenerationConfig\": {\"maxTokenCount\": 1000, \"stopSequences\": [], \"temperature\": 0.5, \"topP\": 0.9}})\n",
    "            response_body = bedrock_client.invoke_model(modelId=llm_model_id, body=body)\n",
    "            llm_answer = json.loads(response_body.get('body').read())['results'][0]['outputText']\n",
    "\n",
    "        print(f\"\\n최종 답변: {llm_answer}\")\n",
    "        return llm_answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n오류 발생: {e}\")\n",
    "        return f\"RAG 처리 중 오류가 발생했습니다: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_index_name = os.getenv(\"OPENSEARCH_TEST_INDEX_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 모델: cohere.embed-multilingual-v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:opensearch:POST https://puwzk1mbr6lqzo7x97d4.us-west-2.aoss.amazonaws.com:443/test-index/_search [status:200 request:0.174s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "검색된 문서 수: 1개\n",
      "--- 검색된 문서 #1 ---\n",
      "221\n",
      "15\n",
      "03 GAY oOlOlA| ete]\n",
      "@ AHA 00/4) Be\n",
      "A O/O|A] Sf HY O|O|A| SAT B= AS. workspace WS SH OfO|A] A|A LOA, Of O]A| SLE MES. FE OOAAY Al “O|O]A| MYA\" SS +B SESNSA oO.\n",
      "© #4 / = ofgjz) wey\n",
      "Deployment 412, workspace= BAY O/O|A\\2 FH B.S Ss olla MHS.\n",
      "Xt 2 oO\n",
      "Aus Aa re\n",
      "MODELER\n",
      "End of Document\n",
      "------------------------\n",
      "\n",
      "Bedrock 모델: anthropic.claude-v2\n",
      "\n",
      "최종 답변: 제공된 자료를 보면 프로젝트 관리에서 특정 프로젝트를 수정하는 방법에 대한 정보가 포함되어 있지 않습니다. 따라서 정확한 답변을 드리기 어렵습니다. 죄송합니다만, 제공된 문서에는 이에 대한 답변이 없습니다. 프로젝트 수정 방법에 대한 질문이시라면, 보다 자세한 정보를 제공해 주시면 감사하겠습니다.\n",
      "질문: 프로젝트 관리에서 특정 프로젝트 수정을 하는 방법은? 순서대로 알려주세요.\n",
      "답변: 제공된 자료를 보면 프로젝트 관리에서 특정 프로젝트를 수정하는 방법에 대한 정보가 포함되어 있지 않습니다. 따라서 정확한 답변을 드리기 어렵습니다. 죄송합니다만, 제공된 문서에는 이에 대한 답변이 없습니다. 프로젝트 수정 방법에 대한 질문이시라면, 보다 자세한 정보를 제공해 주시면 감사하겠습니다.\n"
     ]
    }
   ],
   "source": [
    "# PDF 내용과 관련된 질문으로 테스트\n",
    "# 프로젝트 관리: 프로젝트 관리 페이지에서 어떤 작업을 할 수 있습니까?\n",
    "# 워크플로우 관리: 워크플로우를 삭제하려면 어떤 버튼을 눌러야 합니까? \n",
    "# 사용자 권한: user001의 워크플로우 권한은 무엇입니까? \n",
    "# 사용자 이관: 사용자의 탈퇴 또는 계정 삭제 시 사용자를 이관하는 기능은 어떤 계정만 가능합니까? \n",
    "\n",
    "query = \"사용자의 탈퇴 또는 계정 삭제 시 사용자를 이관하는 기능은 어떤 계정만 가능합니까?\" # PDF 내용에 따라 질문을 변경하세요.\n",
    "\n",
    "# 다른 일반 사용자 계정인 user001, user002 등은 사용자 이관 기능을 사용할 수 없습니다.\n",
    "# 따라서 사용자 탈퇴나 삭제 시 사용자 이관 기능을 사용할 수 있는 계정은 sso_admin 뿐이라고 답변드리겠습니다. 제공된 자료 내용에 근거한 답변입니다.\n",
    "\n",
    "# query = \"프로젝트 관리에서 특정 프로젝트 수정을 하는 방법은? 순서대로 알려주세요.\"\n",
    "\n",
    "answer = get_rag_answer_from_bedrock_with_embeddings(query)\n",
    "\n",
    "print(f\"질문: {query}\")\n",
    "print(f\"답변: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_index_name = os.getenv(\"OPENSEARCH_TEST_INDEX_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 2. 인덱싱 함수 (텍스트 + 이미지)\n",
    "# ========================\n",
    "def process_pdf_and_index_opensearch_with_images(s3_file_name):\n",
    "    try:\n",
    "        logging.info(\"S3에서 PDF 파일 다운로드 중...\")\n",
    "        s3_object = s3_client.get_object(Bucket=s3_bucket_name, Key=s3_file_name)\n",
    "        pdf_content = s3_object['Body'].read()\n",
    "        logging.info(\"다운로드 완료.\")\n",
    "\n",
    "        logging.info(\"unstructured를 사용하여 PDF 내용 분할 중...\")\n",
    "        elements = partition_pdf(\n",
    "            file=BytesIO(pdf_content),\n",
    "            strategy=\"hi_res\",\n",
    "            infer_table_structure=False,\n",
    "            languages=[\"kor\", \"eng\"],\n",
    "            extract_images_in_pdf=True,\n",
    "            image_output_dir_path=\"./images\"\n",
    "        )\n",
    "        logging.info(f\"unstructured 분할 완료. 추출된 요소 수: {len(elements)}\")\n",
    "\n",
    "        pages = {}\n",
    "        for el in elements:\n",
    "            page_num = el.metadata.page_number if hasattr(el.metadata, 'page_number') else None\n",
    "            if page_num not in pages:\n",
    "                pages[page_num] = {'text': [], 'images': []}\n",
    "            \n",
    "            if el.text:\n",
    "                pages[page_num]['text'].append(el.text)\n",
    "            \n",
    "            if hasattr(el.metadata, 'image_path') and el.metadata.image_path:\n",
    "                pages[page_num]['images'].append(os.path.basename(el.metadata.image_path))\n",
    "\n",
    "            \n",
    "        # OpenSearch 인덱스 존재 여부 확인 및 생성\n",
    "        index_exists = True\n",
    "        try:\n",
    "            opensearch_client.indices.get(index=opensearch_index_name)\n",
    "        except NotFoundError:\n",
    "            index_exists = False\n",
    "\n",
    "        if index_exists:\n",
    "            print(f\"OpenSearch 인덱스 '{opensearch_index_name}'이(가) 이미 존재합니다.\")\n",
    "            opensearch_client.indices.delete(index=opensearch_index_name)\n",
    "            print(f\"OpenSearch 인덱스 '{opensearch_index_name}'이(가) 삭제 완료\")\n",
    "        else:\n",
    "            print(f\"OpenSearch 인덱스 '{opensearch_index_name}'이(가) 존재하지 않습니다. 새로 생성합니다.\")\n",
    "        \n",
    "        mapping = {\n",
    "            \"settings\": {\n",
    "                \"index.knn\": True,\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"text\": {\"type\": \"text\"},\n",
    "                    \"embedding\": {\n",
    "                        \"type\": \"knn_vector\",\n",
    "                        \"dimension\": 1024,\n",
    "                        \"method\": {\n",
    "                            \"name\": \"hnsw\",\n",
    "                            \"engine\": \"nmslib\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"image_paths\": {\"type\": \"keyword\"},\n",
    "                    \"page_number\": {\"type\": \"long\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "                \n",
    "        opensearch_client.indices.create(index=opensearch_index_name, body=mapping)\n",
    "        logging.info(f\"OpenSearch 인덱스 '{opensearch_index_name}' 생성 완료.\")\n",
    "\n",
    "        docs = []\n",
    "        for page_num, content in pages.items():\n",
    "            if not content['text'] and not content['images']:\n",
    "                continue\n",
    "            combined_text = \"\\n\".join(content['text'])\n",
    "            \n",
    "            bedrock_model_id = 'cohere.embed-multilingual-v3'\n",
    "            response = bedrock_client.invoke_model(\n",
    "                modelId=bedrock_model_id,\n",
    "                body=json.dumps({\"texts\": [combined_text], \"input_type\": \"search_document\"})\n",
    "            )\n",
    "            embedding = json.loads(response['body'].read())['embeddings'][0]\n",
    "\n",
    "            doc = {\n",
    "                'text': combined_text,\n",
    "                'source': s3_file_name,\n",
    "                'page_number': page_num,\n",
    "                'embedding': embedding,\n",
    "                'image_paths': content['images']\n",
    "            }\n",
    "            docs.append({\n",
    "                '_index': opensearch_index_name,\n",
    "                '_source': doc\n",
    "            })\n",
    "\n",
    "        bulk(opensearch_client, docs)\n",
    "        logging.info(f\"PDF 내용 및 이미지 정보가 OpenSearch에 성공적으로 인덱싱되었습니다. 문서 수: {len(docs)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 3. RAG 함수 (하이브리드 검색 + 이미지 출력)\n",
    "# ========================\n",
    "def get_rag_answer_from_bedrock_with_images(query):\n",
    "    try:\n",
    "        bedrock_model_id_embedding = 'cohere.embed-multilingual-v3'\n",
    "        response = bedrock_client.invoke_model(\n",
    "            modelId=bedrock_model_id_embedding,\n",
    "            body=json.dumps({\"texts\": [query], \"input_type\": \"search_query\"})\n",
    "        )\n",
    "        query_embedding = json.loads(response['body'].read())['embeddings'][0]\n",
    "        \n",
    "        search_query = {\n",
    "            \"size\": 3,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\": [\n",
    "                        {\n",
    "                            \"multi_match\": {\n",
    "                                \"query\": query,\n",
    "                                \"fields\": [\"text^2\"]\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"knn\": {\n",
    "                                \"embedding\": {\n",
    "                                    \"vector\": query_embedding,\n",
    "                                    \"k\": 3\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"minimum_should_match\": 1\n",
    "                }\n",
    "            },\n",
    "            \"_source\": [\"text\", \"image_paths\"]\n",
    "        }\n",
    "        \n",
    "        response = opensearch_client.search(index=opensearch_index_name, body=search_query)\n",
    "        hits = response['hits']['hits']\n",
    "        context_docs = []\n",
    "        image_paths = []\n",
    "        \n",
    "        for hit in hits:\n",
    "            context_docs.append(hit['_source']['text'])\n",
    "            if 'image_paths' in hit['_source'] and hit['_source']['image_paths']:\n",
    "                image_paths.extend(hit['_source']['image_paths'])\n",
    "        \n",
    "        if not context_docs:\n",
    "            return \"죄송합니다. 질문에 대한 관련 문서를 찾을 수 없습니다.\", []\n",
    "\n",
    "        context = \"\\n\\n\".join(context_docs)\n",
    "        \n",
    "        llm_model_id = os.getenv(\"BEDROCK_MODEL_ID\")\n",
    "        \n",
    "        if 'claude' in llm_model_id:\n",
    "            prompt = f\"\"\"\n",
    "            다음은 사용자 질문에 답변하기 위한 참고 자료입니다.\n",
    "            <자료>\n",
    "            {context}\n",
    "            </자료>\n",
    "            당신은 유용한 AI 비서입니다. 제공된 자료만을 바탕으로 사용자의 질문에 한국어로 상세하고 친절하게 답변해주세요. 만약 자료에 답변이 없다면, \"죄송합니다. 제공된 문서에는 답변이 없습니다.\"라고 말해주세요. 절대 자료에 없는 정보를 임의로 생성하지 마세요.\n",
    "            사용자 질문: {query}\n",
    "            답변:\n",
    "            \"\"\"\n",
    "            body = json.dumps({\"anthropic_version\": \"bedrock-2023-05-31\", \"max_tokens\": 1000, \"messages\": [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}], \"temperature\": 0.5})\n",
    "            response_body = bedrock_client.invoke_model(modelId=llm_model_id, body=body, contentType=\"application/json\", accept=\"application/json\")\n",
    "            llm_answer = json.loads(response_body.get('body').read())['content'][0]['text']\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "            You are a helpful AI assistant. Use only the provided context to answer the user's question in Korean. If the answer is not in the context, say \"죄송합니다. 제공된 문서에는 답변이 없습니다.\" Do not make up information.\n",
    "            Context:\n",
    "            {context}\n",
    "            Question: {query}\n",
    "            Answer:\n",
    "            \"\"\"\n",
    "            body = json.dumps({\"inputText\": prompt, \"textGenerationConfig\": {\"maxTokenCount\": 1000, \"stopSequences\": [], \"temperature\": 0.5, \"topP\": 0.9}})\n",
    "            response_body = bedrock_client.invoke_model(modelId=llm_model_id, body=body)\n",
    "            llm_answer = json.loads(response_body.get('body').read())['results'][0]['outputText']\n",
    "\n",
    "        unique_image_paths = list(set(image_paths))\n",
    "        return llm_answer, unique_image_paths\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"RAG 처리 중 오류가 발생했습니다: {e}\", []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:S3에서 PDF 파일 다운로드 중...\n",
      "INFO:root:다운로드 완료.\n",
      "INFO:root:unstructured를 사용하여 PDF 내용 분할 중...\n",
      "INFO:unstructured:PDF text extraction failed, skip text extraction...\n",
      "INFO:unstructured_inference:Reading PDF for file: /var/folders/bn/5hyhxy6d0293c60lhm7g3dc40000gn/T/tmpk_7qzxxl/document.pdf ...\n",
      "WARNING:unstructured:short text: \"Acculnsight+ 2.0 #e2|At WS\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"2021. 09 DataSet\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"i SK SIA} C&C\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"01 ZRAE Fel\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"PIPELINE\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"/Q |\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"demo-for-mosiler\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \";\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"=\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"test22\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"AAS\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"0\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \";\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"| 01\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"[HO OS o [He\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"Jlo\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"|\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"Jlo\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"PIPELINE\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"01 BAAR tel\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"PIPELINE\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"03 HABeFP. Fil\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"PIPELINE\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"Select Project\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"03 HALO Beal\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"PIPELINE\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"wu\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"PIPELINE\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"PIPELINE\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"ISH o\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"04 AFHA; Ast Zte|\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"4\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"PIPELINE\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"PIPELINE\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"05 AFSAt Ol zt\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"PIPELINE\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"Select Project\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"ae{4F\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"wate\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"ASAT 0] Zt\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"ag\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"A718\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"oleh St AKA Ais\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"10\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"01 ZRAE Fel\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"MODELER\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"11\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"r\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"2] Resource Quota\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"3) Members\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"MODELER\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"O02 AfSA} Bel\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"MODELER\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"13\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"Ba 02 AFSAt\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"= Ly ial aa\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"Jlo (e)\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"WI ra l4| ral\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"_ zt (e)\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"MODELER\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"03 GAY oOlOlA| ete]\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"MODELER\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"221\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"15\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"03 GAY oOlOlA| ete]\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"@ AHA 00/4) Be\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"Xt 2 oO\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"Aus Aa re\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"MODELER\". Defaulting to English.\n",
      "WARNING:unstructured:short text: \"End of Document\". Defaulting to English.\n",
      "INFO:root:unstructured 분할 완료. 추출된 요소 수: 109\n",
      "WARNING:opensearch:GET https://puwzk1mbr6lqzo7x97d4.us-west-2.aoss.amazonaws.com:443/test-index [status:404 request:0.176s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSearch 인덱스 'test-index'이(가) 존재하지 않습니다. 새로 생성합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:opensearch:PUT https://puwzk1mbr6lqzo7x97d4.us-west-2.aoss.amazonaws.com:443/test-index [status:200 request:0.350s]\n",
      "INFO:root:OpenSearch 인덱스 'test-index' 생성 완료.\n",
      "INFO:opensearch:POST https://puwzk1mbr6lqzo7x97d4.us-west-2.aoss.amazonaws.com:443/_bulk [status:200 request:11.522s]\n",
      "INFO:root:PDF 내용 및 이미지 정보가 OpenSearch에 성공적으로 인덱싱되었습니다. 문서 수: 18\n"
     ]
    }
   ],
   "source": [
    "# 함수 호출\n",
    "process_pdf_and_index_opensearch_with_images(s3_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_index_name = os.getenv(\"OPENSEARCH_TEST_INDEX_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:opensearch:POST https://puwzk1mbr6lqzo7x97d4.us-west-2.aoss.amazonaws.com:443/test-index/_search [status:200 request:0.255s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 프로젝트 관리에서 특정 프로젝트 수정을 하는 방법은? 순서대로 알려주세요.\n",
      "답변: ('제공된 자료에 따르면, 프로젝트 관리에서 특정 프로젝트를 수정하는 방법은 다음과 같습니다:\\n\\n1. 프로젝트 관리 페이지로 이동합니다.\\n\\n2. 수정하려는 프로젝트를 선택합니다. \\n\\n3. 프로젝트 정보 옆의 편집 아이콘을 클릭합니다.\\n\\n4. 프로젝트 정보 수정 페이지에서 프로젝트 이름, 설명, 사용자 등을 수정합니다.\\n\\n5. 저장 버튼을 클릭하여 수정된 내용을 저장합니다.\\n\\n이와 같은 절차를 통해 프로젝트 관리에서 특정 프로젝트를 수정할 수 있습니다. 제공된 자료에서 확인할 수 있듯이 프로젝트를 선택하고 편집 아이콘을 클릭하여 수정 페이지로 이동한 후 정보를 수정하고 저장하면 됩니다.', ['figure-9-5.jpg'])\n"
     ]
    }
   ],
   "source": [
    "# PDF 내용과 관련된 질문으로 테스트\n",
    "# 프로젝트 관리: 프로젝트 관리 페이지에서 어떤 작업을 할 수 있습니까?\n",
    "# 워크플로우 관리: 워크플로우를 삭제하려면 어떤 버튼을 눌러야 합니까? \n",
    "# 사용자 권한: user001의 워크플로우 권한은 무엇입니까? \n",
    "# 사용자 이관: 사용자의 탈퇴 또는 계정 삭제 시 사용자를 이관하는 기능은 어떤 계정만 가능합니까? \n",
    "\n",
    "# query = \"사용자의 탈퇴 또는 계정 삭제 시 사용자를 이관하는 기능은 어떤 계정만 가능합니까?\" # PDF 내용에 따라 질문을 변경하세요.\n",
    "\n",
    "# 다른 일반 사용자 계정인 user001, user002 등은 사용자 이관 기능을 사용할 수 없습니다.\n",
    "# 따라서 사용자 탈퇴나 삭제 시 사용자 이관 기능을 사용할 수 있는 계정은 sso_admin 뿐이라고 답변드리겠습니다. 제공된 자료 내용에 근거한 답변입니다.\n",
    "\n",
    "query = \"프로젝트 관리에서 특정 프로젝트 수정을 하는 방법은? 순서대로 알려주세요.\"\n",
    "\n",
    "answer = get_rag_answer_from_bedrock_with_images(query)\n",
    "\n",
    "print(f\"질문: {query}\")\n",
    "print(f\"답변: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit_pdf_viewer\n",
      "  Downloading streamlit_pdf_viewer-0.0.26-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: streamlit>=0.63 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit_pdf_viewer) (1.30.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (8.1.8)\n",
      "Requirement already satisfied: importlib-metadata<8,>=1.4 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (6.11.0)\n",
      "Collecting numpy<2,>=1.19.3 (from streamlit>=0.63->streamlit_pdf_viewer)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (2.2.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (10.4.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (4.25.8)\n",
      "Requirement already satisfied: pyarrow>=6.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (19.0.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (13.9.4)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (4.13.2)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (5.3)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (0.34.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from streamlit>=0.63->streamlit_pdf_viewer) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_pdf_viewer) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_pdf_viewer) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_pdf_viewer) (1.26.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_pdf_viewer) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_pdf_viewer) (5.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from importlib-metadata<8,>=1.4->streamlit>=0.63->streamlit_pdf_viewer) (3.21.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit_pdf_viewer) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit_pdf_viewer) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from python-dateutil<3,>=2.7.3->streamlit>=0.63->streamlit_pdf_viewer) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_pdf_viewer) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_pdf_viewer) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_pdf_viewer) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_pdf_viewer) (2025.4.26)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_pdf_viewer) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_pdf_viewer) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit_pdf_viewer) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_pdf_viewer) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_pdf_viewer) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_pdf_viewer) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_pdf_viewer) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kwon/miniconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit_pdf_viewer) (0.1.0)\n",
      "Downloading streamlit_pdf_viewer-0.0.26-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl (20.3 MB)\n",
      "Installing collected packages: numpy, streamlit_pdf_viewer\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [streamlit_pdf_viewer]eamlit_pdf_viewer]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "llama-index-core 0.13.2 requires nltk>3.8.1, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4 streamlit_pdf_viewer-0.0.26\n"
     ]
    }
   ],
   "source": [
    "# !pip install streamlit_pdf_viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
